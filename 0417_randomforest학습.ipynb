{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest 내용실습\n",
    "https://mozenworld.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EC%86%8C%EA%B0%9C-4-%EB%9E%9C%EB%8D%A4-%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8-Random-Forest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤포레스트의 특징\n",
    "- 앙상블 학습 방법 중 하나. 여러개의 결정트리를 조합하여 강력한 분류 모델을 구축하는 방법. \n",
    "- 과적합(Overfitting)을 줄이고 예측성능 개선에 효과적\n",
    "\n",
    "- 지도학습 알고리즘 & 의사결정나무 조합 모델\n",
    "    - 의사결정나무는 if-else로 이루어짐. 나무모형으로 중간마디(internal node)와 끝마디(leaf node)로 구성된 형태\n",
    "- 마디마다 두개의 자식마디로 분할. 끝에 오는 마디가 출력변수 y( = ㅣleaf model)\n",
    "- 분류나무(classification): 분류 목적. 출력 변수가 범주형 변수(dummy variable) \n",
    "- 회귀나무(regression): 추론하는 변수가 연속형 실수\n",
    "\n",
    "\n",
    "- 결국 랜덤포레스트는 의사결정나무 + 배깅(bagging) = 앙상블학습 적용\n",
    "    - 앙상블은 종류에 따라 배깅, 부스팅, 스택킹으로 분류\n",
    "    - bagging은 분산(variance)를 줄이기 위해 사용. \n",
    "- 랜포 단점: 계산 비용이 높고 규칙이 많아 추론 로직이 설명하기 난해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 의사 결정나무는 탐욕재귀분할 알고리즘\n",
    "\n",
    "- 의사결정나무는 greedy recursive partitioning algorithm(탐욕 재귀 분할 알고리즘)에서 형성\n",
    "- 탐욕알고리즘은 각 단계에서 국소최적해(local minimum) 선택\n",
    "    - 이로 인해 최종해가 global optimum보장이 되지 않음\n",
    "- 각 나무의 성장은 불순도에 따라 재귀적으로 분할\n",
    "    - 불순도 지표: 지니(Gini index)나 엔트로피(entropy)사용\n",
    "    - 회귀문제에서는 평균제곱오차(Mean Square Error, MSE)를 불순도 지표로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤포레스트 작동방식\n",
    "- 여러개의 의사나무를 구성하여 의사결정 나무의 예측 결과를 다수결로 조합하여 최종 예측 결과를 결정하는 방식\n",
    "- 각 랜덤트리는 랜덤하게 선택된 데이터 샘플과 독립된 변수들을 사용하여 학습\n",
    "    - 이러한 과정을 통해 상호보완적 예측이 가능해지고 강력한 예측을 수행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#독립변수\n",
    "X = iris.data\n",
    "#종속변수\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 분리\n",
    "- train_test_split함수로 세트나누기\n",
    "- test_size = 0.2 => 20%를 테스트데이터로 설정\n",
    "- random_state = 42 => 재현성 확보. 랜덤으로 뽑고 상태 고정(아무숫자 넣어도됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤포레스트 모델 초기화\n",
    "model = RandomForestClassifier()\n",
    "# 모델 학습 시키기\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측 y_pred\n",
    "y_pred = model.predict(X_test)\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
